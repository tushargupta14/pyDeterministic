%%% Uncertainity Quantification

\chapter{Optimal Control using Uncertainity Quantification}

\paragraph{Kinetic parameters} are generally empirical constants determined by fitting experimental data to the model, and, hence, are a source of uncertainty within the system. Two methods are discussed here to quantify these uncertainities and thereby perform build a more robust dynamic optimization.

\section{Stochastic Optimal Control using Ito Processes}

From several previous works it has been shown that the dynamic uncertainties
such as the batch reactors\cite{benavides2} and batch distillation,\cite{diwekar}, can be represented using stochastic processes called as the Ito processes.  We characterize the time-dependent uncertainties in the state variables using Ito processes.\\
The advantage lies in the ability to integrate the equations using the principles of stochastic calculus and the use of stochastic maximum principle to solve for the optimal temperature profile. \\
In batch crystallization kinetics, the growth and nucleation expressions have empirical constants shown in Table \ref{Table1}, they can be assumed to follow a Gaussian distribution\cite{yenkie}. By studying the nature of the dynamic uncertainty plots of the process variables and their correlation to Ito processes, it has been observed that the uncertainties can be best modeled with a simple Ito process known as \textbf{Brownian motion} with drift\cite{diwekar,wong}. It can be defined as:
\begin{equation} \label{gen}
dy = a(y,t)dt + b(y,t)dz
\end{equation}
where $dz$ is the increment of the Wiener process equal to $\varepsilon_{t}(\Delta t)^{1/2}$, and a(y,t) and b(y,t) are known functions. The random value $\varepsilon_{t}$  has a unit normal distribution with zero mean
and a standard deviation of 1. To estimate the values of the functions a and b, a generalized method presented by Diwekar\cite{diwekar} has been used.\\
In this work, equation(\ref{gen}) has been used to incorporate the uncertainties into the moment equations which are\cite{yenkie} :
\begin{align}
dy_{1} &= \left[-3\rho k_{v}G(t)(y_{4}+y{8})\right]\Delta t + g_{1}\varepsilon_{1}\sqrt{\Delta t} \\
dy_{2} &= 0 \\
dy_{3} &= (G(t)y_{2})\Delta t +g_{3}\varepsilon_{3}\sqrt{\Delta t} \\
dy_{4} &= (2G(t)y_{3})\Delta t + g_{4}\varepsilon_{4}\sqrt{\Delta t} \\
dy_{5} &= (3G(t)y_{4})\Delta t + g_{5}\varepsilon_{5}\sqrt{\Delta t} \\
dy_{6} &= (B(t))\Delta t + g_{6}\varepsilon_{6}\sqrt{\Delta t} \\
dy_{7} &= (G(t)y_{6})\Delta t + g_{7}\varepsilon_{7}\sqrt{\Delta t} \\
dy_{8} &= (2G(t)y_{7})\Delta t +g_{8}\varepsilon_{8}\sqrt{\Delta t} \\
dy_{9} &= (3G(t)y_{8})\Delta t + g_{9}\varepsilon_{9}\sqrt{\Delta t} \\
\end{align}
$a(y,t)$ in each equation is replaced by the corresponding deterministic function   for the state variable.\\
Here, the $g_{i}$ values represent the variance in the variable for which they are associated. They are calculated by recording the variance of the differences in $y_{i}$, which is divided by the time
interval $\Delta t$, and then the square root of this value is taken.


\paragraph{Objective Function} for the stochastic formulation now becomes :
\begin{equation} \label{objective}
\max_{T} L = \mathbf{E}\left[ \mu_{3}^{s}(t_{f}) - \mu_{3}^{n}(t_{f})\right]
\end{equation}
$\mathbf{E}$ is the expected value of the variable. \\
The \textbf{Active Constraints} and \textbf{Initial Conditions} remain the same as mentioned in Section (\ref{deterministic}).

\subsection{Solution Technique : Stochastic Steepest Ascent Hamiltonian}

The Hamiltonian for this section is modified to incorporate the uncertainities as\cite{yenkie} :
\begin{equation}
H = \sum_{i=1}^{9} \left( z_{i}f_{i} + \omega_{i}\frac{g_{y_{i}}^2}{2} \right)
\end{equation}
$f_{i}$ are the deterministic parts for the eq (5.2-5.11). $\omega_{i}$ is an additional adjoint variable defined to calculate the Hamiltonian for the \textbf{Stochastic Maximum Principle} formulation\cite{ramirez}.  

The \textbf{Algorithm} for the method remains same as mentioned in Section (4.1.1) with minor changes.
\begin{enumerate}
\item  Steps (1-4) are repeated. 
\item The variable θi corresponds to each of the state variable yi and the variable ∮ i corresponds to each of the adjoint variable zi , Ψi corresponding to each ωi respectively.
\item The variable $\theta_{i}$ corresponds to each of the state variable $y_{i}$ and the variable $\phi_{i}$ corresponds to each of the adjoint variable $z_{i}$, $\psi_{i}$ for each $\omega_{i}$ respectively.

\item The Hamiltonian derivative is now calculated at each time step  as :
\begin{align}
&\theta = \frac{dy_{i}}{dT} \quad \phi_{i} = \frac{dz_{i}}{dT} \quad \psi = \frac{d\omega_{i}}{dT} \\
&\frac{dH}{dT} = \sum_{i=1}^{9} \left( \frac{dH}{dy_{i}}\right)\left(	\frac{dy_{i}}{dT} \right) + \sum_{i=1}^{9} \left(\frac{dH}{dz_{i}}\right)\left(\frac{dz_{i}}{dT} \right) + \sum_{i=1}^{9} \left(\frac{dH}{dw_{i}}\right)\left(\frac{dw_{i}}{dT} \right)
\end{align}
\item The convergence criteria and the constraints remain same as the above referenced method.
\end{enumerate} 


\subsection{Results}
The following values were used as the coefficients for uncertainities for the state variables :
\begin{center}
\begin{table}[!h]
\centering
\caption{State Variable Uncertainity Coefficients\cite{yenkie}}
\begin{tabular}{|c|c|}
\hline
Parameters & Values \\
\hline
$g_{1}$ & $2.659\times10^{-5}$ \\
$g_{2}$ & $0$ \\
$g_{3}$ & $25.882$ \\
$g_{4}$ & $1.517\times10^{4}$ \\ 
$g_{5}$ & $6.57\times10^{6}$ \\
$g_{6}$ & $0.5486$ \\
$g_{7}$ & $25.9$\\
$g_{8}$ & $1382.34$ \\
$g_{9}$ & $8.753\times10^{4}$ \\
\hline
\end{tabular}

\label{Table2}
\end{table}
\end{center}

\begin{itemize}
\item The stochastic differential equations are integrated using stochastic calculus through \textbf{SDE Tools} Library available in \textbf{Matlab}.A strong Taylor approximation from the \textbf{Euler Maruyama} scheme has been used to integrate the equations which has an order of convergence of 0.5. 
\end{itemize}
The following profiles were obtained as a result :
\begin{figure}[h!] 

\begin{center}
\includegraphics[width=4in]{Sobj.png}
\end{center}
\caption{Objective Function ($\mathbf{E}\left[\mu_{3}^{s}(t) - \mu_{3}^{n}(t)\right]$)}
\end{figure}
\begin{figure}[h!] 

\begin{center}
\includegraphics[width=4in]{Stemp.png}
\end{center}
\caption{The cooling profile for the controlled variable T(t) obtained at the final iteration}
\end{figure}

\begin{figure}[h!] 

\begin{center}
\includegraphics[width=4in]{Sconc.png}
\end{center}
\caption{Concentration Profile as obtained}
\end{figure}
\clearpage

\section{Stochastic Optimal Control using Polynomial Chaos Expansions}

\subsection{Introduction}
A Polynomial Chaos Expansion (PCE) describes a random process as a spectral expansion of random variables($\theta_{i}$), using orthogonal basis functions, $\Phi_{i}$ (Ghanem and Spanos, 1990,Ghanem and Spanos, 1997). For example, any second-order (finite variance) random process $y^{d}$, can be described using a PCE as follows:
\begin{equation}
y^{d} = a_{0}^{d}\phi_{0} + \sum_{i_{1}=1}^{\infty} a_{i_{1}}^{d}\phi_{1}(\theta_{i_{i1}}) + \sum_{i_{1}=1}^{\infty}\sum_{i_{2}=1}^{i_{1}} a_{i_{1}i_{2}}^d\phi_{2}(\theta_{i_{1}},\theta_{i_{2}})
\end{equation}
where $a_{i_{1}}^d$  are deterministic coefficients for each term in the expansion. The number of independent sources of random variables $(\theta_{i_{1}}, \theta_{i_{2}})$, generally defines the dimensionality, $n_{0}$. For practical application these expansions can be
truncated to a finite number of terms. Then the maximum polynomial order for the basis function, q needs to be defined.
The number of terms now become $P_{PCE} = \frac{(n_{0}+q)!}{n_{0}!q!} -1 $. \\
Using these notations a truncated PCE expansion can be represented as follows:
\begin{equation} 
\label{poly}
y^{d} \approx \sum_{i=1}^{P_{PCE}} a_{i}^{d}\phi_{\theta}
\end{equation}

The orthogonality property of the basis functions($\phi_{i}$) is used for the  calculation of the coefficients when propagating uncertainty from the input random variables$(\theta_{i_{1}}, \theta_{i_{2}})$, to the output random
variables ($y^{d}$).\\
The choice of the basis functions $\phi_{i}$ depends on the type of stochastic distribution to be represented, i.e. normal or uniform. In our case the parameters follow a Gaussian distribution\cite{yenkie}, which uses Hermite Polynomials to describe the probability distribution in the least number of terms.\\
Thus, given a process model with uncertain output, $y = X(x,\lambda)$, where $x$ is the uncertain input and $\lambda$ is the uncertain parameter, the aim is to quantify uncertainty in $y(\theta)$ from $x(\theta), \lambda(\theta)$ using the process model. Then the first step is to construct PCE’s of $x(\theta)$, and $\lambda(\theta)$, by determining their PCE coefficients $x_{i}$ and $\lambda_{i}$.
\begin{align}
&x(\theta) = \sum_{i=1}^{P_{PCE}} x_{i}\phi(\theta)
&\lambda(\theta) = \sum_{i=1}^{P_{PCE}} \lambda_{i}\phi(\theta)
\end{align}
\begin{equation}
&x_{i} = \frac{\int x\phi_{i}(\theta)g(\theta) d\theta}{\left\langle \phi^{2}_{i}\right\rangle } \quad
&\lambda_{i} = \frac{\int \lambda\phi_{i}(\theta)g(\theta) d\theta}{\left\langle \phi^{2}_{i}\right\rangle }
\end{equachaospytion}
where $g(\theta)$ is probability distribution function (pdf) of $\theta$. 
The next step is to develop PCE for $y(\theta)$ from  $x(\theta)$, and $\lambda(\theta)$, which can be done by evaluating the
inner product of $y(\theta)$ with each basis functions $\phi_{i}$ to determine the ith- PCE coefficient.
\begin{equation}
y_{i} = \frac{\left\langle f(x,\lambda)\phi_{i} \right\rangle }{\left\langle \phi^{2}_{i} \right\rangle }
\end{equation}
Evaluating the inner product $\left\langle y\phi_{i} \right\rangle $, requires computation of multi-dimensional integrals which can be performed by one of two approaches referred to as \textbf{non-intrusive} and \textbf{intrusive}.\\
The work under consideration here uses a non-intrusive approach. The model $y=X(x,\lambda)$ is represented by the modelling equations of Section(\ref{modeleq}). $x$ are the state variables and $\lambda$'s are the kinetic parameters.

\subsection{Usage of PCE in Batch Crystallization}

The model under consideration is composed of the state equations and kinetics mentioned in Section(\ref{modeleq}), which are :

\begin{align} 
\frac{dy_{1}}{dt} &= -3\rho k_{v}G(t)(y_{4}+y{8}) \\
\frac{dy_{2}}{dt} &= 0 \\
\frac{dy_{3}}{dt} &= G(t)y_{2}  \\
\frac{dy_{4}}{dt} &= 2G(t)y_{3} \\
\frac{dy_{5}}{dt} &= 3G(t)y_{4} \\
\frac{dy_{6}}{dt} &= B(t)  \\
\frac{dy_{7}}{dt} &= G(t)y_{6}  \\
\frac{dy_{8}}{dt} &= 2G(t)y_{7}  \\
\frac{dy_{9}}{dt} &= 3G(t)y_{8}  \\
\end{align}  

Here, the state varibles($y_{i}$) act as the uncertain outputs which is caused by errors in process parameters used to calculate the Growth rate ($G(t) = k_{g}\exp{\left(-E_{g}/RT \right)}\left(\frac{C - C_{s}(T)}{C_{s}(T)}\right)^{g}$) and the Nucleation rate ($B(t) = k_{b}\exp{\left(-E_{b}/RT \right)}\left(\frac{C - C_{s}(T)}{C_{s}(T)}\right)^{b}\mu_{3}$). As a result, uncertainities in the parameters $\lambda$ ($k_{g}, E_{g}, g, k_{b}, E_{b}, b$) are propogated into the model using P.C.E during optimal control.\\
A non-intrusive approach is followed for the above task where the integrals are calculated by generating samples of the above process and evaluating the model at these pre-determined points.
\paragraph{Algorithm} is as follows : 
\begin{enumerate}
\item Following the general representation, $y_{i}$ can be written as :
\begin{align*}
y_{i} = f(x(\theta),\lambda_{i}(\theta))
\end{align*}
where x is the input temperature(T), $\lambda_{i}$'s are process the parameters and $\theta$ is the random variable.
%% Can add a example expression here
\item The process model consists of 6 uncertainities which computationally prohibits the evaluation. Thus, an approximation of $n_{0} = 2$ is taken by employing a joint distribution of the parameters.
\item Samples are generated for the model at $N$ points. The sampling technique used is the Gaussian Quadratures along with Hermite Polynomials to represent state variables $(y_{i})$ into Eq(5.17).

\item For each of the above sample $y^{j}_{i} = f(T^{j}(\theta),\lambda(\theta) $ ,  the optimization problem is solved using the Steepest Ascent Hamiltonian method discussed in Section(4.1.1).

\item The optimum value of the input temperature $T^{j}(\theta)$ at these samples is used to construct the PCE's for $T(\theta)$ and $\lambda(\theta)$ as given by Equations(5.18).

\item $y^{j}_{i}$'s for each sample are used to evaluate :
\begin{equation}
y_{i} = \frac{1}{\left\langle \phi^{2}_{i}\right\rangle }\frac{1}{N} \sum_{j=1}^{N} y^{j}\phi_{i}(\theta)
\end{equation}
Here, $\phi_{i}$ are the coefficients of the orthogonal polynomials being used for PCE estimation.  

\item As the above Equation averages over N samples, the resultant $y_{i}$ maximises the objective function, given by $ \mathbf{E} \left\lbrace  y_{5}-y_{9} \right\rbrace $). 

\end{enumerate} 

The kinetic parameter values used for the above model are given below :
\begin{center}
\begin{table}[!h]
\centering
\caption{Kinetic Parameter Uncertainities\cite{hu,shi,paeng}}
\begin{tabular}{|c|c|c|}
\hline
Parameters & Experimental Values & Range of Values\\
\hline
\multicolumn{3}{|c|}{Growth Kinetics} \\
\hline
$k_{g}$ & $1.44\times10^{8} \mu m s^{-1}$ & $1.368 - 1.512\times10^{8} $\\
$E_{g}/R$ & $4859K$ & $4606.15-5101.95$\\
$g$ & $1.5$ & $1.425-1.575$\\
\hline
\multicolumn{3}{|c|}{Nucleation Kinetics} \\
\hline
$k_{b}$ & $285 (s \mu m^{3})^{-1}$ & $270.75-299.25$\\ 
$E_{b}/R$ & $7517K$ & $7141.15-7892.85$\\
$b$ & $1.45$ & $1.3775-1.5225$\\
\hline
\end{tabular}

\label{Table3}
\end{table}
\end{center}



\subsection{Results}

\begin{itemize}
\item The method was implemented in pyhton using the \textbf{chaospy} library\cite{chaospy} for Polynomial Chaos Expnasions. 
\end{itemize}
The following profiles were obtained : 

\begin{figure}[h!] 

\begin{center}
\includegraphics[width=4in]{PCEobj.png}
\end{center}
\caption{Objective Function ($\mathbf{E}\left[\mu_{3}^{s}(t) - \mu_{3}^{n}(t)\right]$)}
\end{figure}
\begin{figure}[h!] 

\begin{center}
\includegraphics[width=4in]{PCETemp2.png}
\end{center}
\caption{The cooling profile for the controlled variable T(t) obtained at the final iteration}
\end{figure}

\begin{figure}[h!] 

\begin{center}
\includegraphics[width=4in]{PCEConc.png}
\end{center}
\caption{The concentration profile as obtained.}
\end{figure}
\clearpage

\section{Conclusions}
\begin{itemize}
\item The same process was optimized using 3 different methods of Optimization. This achieves the aim of maximising the volume of the product obtained. 
\item The Temperature profile for all the 3 cases was obtained as a decreasing one and thus follows the principle of batch cooling crystallization. 
\item Polynomial Chaos Expansions, when applied to crystallization performs at par with the existing methods in optimizing the process by efficiently incorporating uncertainities. 
\item After comparing the final values of the objective functions($\mu_{3}^{s}-\mu_{3}^{n}$)[particle volume] the following values were obtained : 
\begin{enumerate}
\item Deterministic : $ 9.153 \times 10^{9} \mu m^{3}$
\item Expected value for Stochastic involving Ito Processes : $8.978 \times 10^{9} \mu m^{3}$
\item Expected value for Stochastic case involving PCE : $8.64 \times 10^{9} \mu m^{3}$
\end{enumerate}
\item The decrease of values can be attributed to the presence of errors or uncertainities in the kinetic parameters. Thus, the model becomes helpful in predicting the expected values for volume of crystals taking care of the process uncertainities.
\end{itemize}